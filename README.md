# ğŸ“Š ETL Pipeline â€“ AnyoneAI Sprint Project 01

This repository contains the implementation of an **ETL pipeline (Extract â†’ Transform â†’ Load)** built in **Python 3.8.10**.  
The pipeline extracts raw CSV data, transforms it using SQL queries, and loads the results into a database for further analysis.  

---

## ğŸ“‚ Project Structure
```

assignment/
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ src/                    # Pipeline source code
â”‚   â”œâ”€â”€ **init**.py
â”‚   â”œâ”€â”€ config.py           # Configuration and paths
â”‚   â”œâ”€â”€ extract.py          # Data extraction and initial cleaning
â”‚   â”œâ”€â”€ transform.py        # SQL queries and transformations
â”‚   â”œâ”€â”€ load.py             # Load into database
â”‚   â”œâ”€â”€ utils.py            # Helper functions
â”‚   â””â”€â”€ run\_pipeline.py     # Main entrypoint to run the ETL
â”œâ”€â”€ queries/                # SQL files used in transformations
â”œâ”€â”€ dataset/                # Original CSV datasets
â””â”€â”€ tests/                  # Unit tests with pytest

````

---

## âš™ï¸ Requirements
- Python **3.8.10**  
- Pip (latest version)  
- All dependencies are pinned in `requirements.txt`  

---

## ğŸš€ Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/josedaniel-dev/etl-pipeline.git
   cd etl-pipeline
````

2. Create and activate a virtual environment:

   ```bash
   python -m venv venv_38
   source venv_38/bin/activate   # Linux / macOS
   venv_38\Scripts\activate      # Windows
   ```

3. Install dependencies:

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ Running the Pipeline

Execute the full ETL workflow:

```bash
python -m src.run_pipeline
```

Steps performed:

1. **Extract** â†’ Reads CSV files from `dataset/` and applies initial cleaning.
2. **Transform** â†’ Runs SQL queries stored in `queries/`.
3. **Load** â†’ Saves transformed data into the database.

---

## ğŸ§ª Tests

Unit tests are included with **pytest**:

```bash
pytest -q
```

All tests should pass âœ….

---

## ğŸ“Œ Notes

* Tested with **Python 3.8.10**, `pandas==1.5.3`, and `SQLAlchemy==1.4.52`.
* Do not commit virtual environments (`venv/`), `__pycache__/`, or temporary files.
* The `queries/` folder contains all SQL transformations.
* The `dataset/` folder contains the original CSV files.

---

## ğŸ‘¨â€ğŸ’» Author

**Jose Daniel Soto**

* GitHub: [josedaniel-dev](https://github.com/josedaniel-dev)
* LinkedIn: [linkedin.com/in/josedanielsoto](https://www.linkedin.com/in/josedanielsoto/)

---

âœ¨ Developed as part of the **AnyoneAI Program**.

---